{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WorqHat/Langchain-Example/blob/main/Langchain_WorqhatAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jJjC5UQhwLY",
        "outputId": "bc50eea7-69cb-49ce-dcbe-2eff7c421104"
      },
      "outputs": [],
      "source": [
        "%pip install langchain_core\n",
        "%pip install json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWYrwFLlf5JP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "from typing import Any, List, Mapping, Optional\n",
        "from langchain_core.language_models.llms import LLM\n",
        "from langchain_core.callbacks.manager import CallbackManagerForLLMRun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPxt4793iOwt"
      },
      "outputs": [],
      "source": [
        "class CustomLLM(LLM):\n",
        "    \"\"\"\n",
        "    CustomLLM is a custom language model that interfaces with the Worqhat API to generate text based on a prompt.\n",
        "    It supports additional parameters for fine-tuning the response, including training data for few-shot learning,\n",
        "    control over the randomness of the response, and the ability to preserve conversation history.\n",
        "\n",
        "    Attributes:\n",
        "        n (int): An identifying parameter for instances of this class.\n",
        "    \"\"\"\n",
        "\n",
        "    n: int\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        \"\"\"Defines the type of the language model.\"\"\"\n",
        "        return \"custom\"\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generates a response to the given prompt using the Worqhat API.\n",
        "\n",
        "        Parameters:\n",
        "            prompt (str): The input prompt for the language model.\n",
        "            stop (Optional[List[str]]): A list of stop sequences. Not permitted in this implementation.\n",
        "            run_manager (Optional[CallbackManagerForLLMRun]): A manager for callbacks during the run. Not used.\n",
        "            **kwargs (Any): Additional parameters supported by the API, such as training_data, randomness, etc.\n",
        "\n",
        "        Returns:\n",
        "            str: The generated response from the API.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If stop sequences are provided.\n",
        "            HTTPError: If the API request fails.\n",
        "        \"\"\"\n",
        "        if stop is not None:\n",
        "            raise ValueError(\"stop kwargs are not permitted.\")\n",
        "\n",
        "        url = \"https://api.worqhat.com/api/ai/content/v2\"\n",
        "\n",
        "        # Include additional parameters for API request\n",
        "        payload = json.dumps({\n",
        "            \"question\": prompt,\n",
        "            \"training_data\": kwargs.get(\"training_data\", \"your name is johnny. when user asks whats your name. say johnny\"),\n",
        "            \"preserve_history\": kwargs.get(\"preserve_history\", False),\n",
        "            \"stream_data\": kwargs.get(\"stream_data\", False),\n",
        "            \"history_object\": kwargs.get(\"history_object\", []),\n",
        "            \"randomness\": kwargs.get(\"randomness\", 0.5),\n",
        "            \"response_type\": kwargs.get(\"response_type\", \"text\"),  # The type of response to generate. Options: \"text\", \"json\"\n",
        "            **kwargs\n",
        "        })\n",
        "\n",
        "        headers = {\n",
        "            'Content-Type': 'application/json',\n",
        "            'Accept': 'application/json',\n",
        "            # 'Authorization': f'Bearer {os.getenv(\"WORQHAT_API_KEY\")}'  # Load API key from environment variable\n",
        "            'Authorization': f'Bearer sk-02e44d2ccb164c738a6c4a65dbf75e89'  # Load API key from environment variable\n",
        "        }\n",
        "\n",
        "        response = requests.post(url, headers=headers, data=payload)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.text\n",
        "        else:\n",
        "            response.raise_for_status()\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Mapping[str, Any]:\n",
        "        \"\"\"\n",
        "        Returns identifying parameters for instances of this class.\n",
        "\n",
        "        Returns:\n",
        "            Mapping[str, Any]: A dictionary of identifying parameters.\n",
        "        \"\"\"\n",
        "        return {\"n\": self.n}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZZyBh2wiOqj"
      },
      "outputs": [],
      "source": [
        "llm = CustomLLM(n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "xcI4C90dzsGd",
        "outputId": "2278d9df-a596-4968-d6d2-85b3e7a03ef6"
      },
      "outputs": [],
      "source": [
        "answer = llm.invoke(\"who created you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response_dict = json.loads(answer)\n",
        "try:\n",
        "    # Attempt to parse the 'content' field as JSON\n",
        "    parsed_content = json.loads(response_dict['content'])\n",
        "    response_dict['content'] = parsed_content\n",
        "except json.JSONDecodeError:\n",
        "    # If 'content' is not a valid JSON, leave it as is\n",
        "    pass\n",
        "\n",
        "# Pretty print the JSON output\n",
        "print(json.dumps(response_dict, indent=4))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNgYRCbl6TshLEE7KYekwJa",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
