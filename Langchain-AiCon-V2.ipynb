{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WorqHat/Langchain-Example/blob/main/Langchain_WorqhatAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jJjC5UQhwLY",
        "outputId": "bc50eea7-69cb-49ce-dcbe-2eff7c421104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_core in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.1.29)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain_core) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain_core) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain_core) (0.1.22)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain_core) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain_core) (1.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain_core) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langchain_core) (8.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3->langchain_core) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3->langchain_core) (1.3.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_core) (3.9.15)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1->langchain_core) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain_core) (3.2.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain_core) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain_core) (2023.5.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain_core\n",
        "%pip install json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uWYrwFLlf5JP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "from typing import Any, List, Mapping, Optional\n",
        "from langchain_core.language_models.llms import LLM\n",
        "from langchain_core.callbacks.manager import CallbackManagerForLLMRun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hPxt4793iOwt"
      },
      "outputs": [],
      "source": [
        "class CustomLLM(LLM):\n",
        "    \"\"\"\n",
        "    CustomLLM is a custom language model that interfaces with the Worqhat API to generate text based on a prompt.\n",
        "    It supports additional parameters for fine-tuning the response, including training data for few-shot learning,\n",
        "    control over the randomness of the response, and the ability to preserve conversation history.\n",
        "\n",
        "    Attributes:\n",
        "        n (int): An identifying parameter for instances of this class.\n",
        "    \"\"\"\n",
        "\n",
        "    n: int\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        \"\"\"Defines the type of the language model.\"\"\"\n",
        "        return \"custom\"\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generates a response to the given prompt using the Worqhat API.\n",
        "\n",
        "        Parameters:\n",
        "            prompt (str): The input prompt for the language model.\n",
        "            stop (Optional[List[str]]): A list of stop sequences. Not permitted in this implementation.\n",
        "            run_manager (Optional[CallbackManagerForLLMRun]): A manager for callbacks during the run. Not used.\n",
        "            **kwargs (Any): Additional parameters supported by the API, such as training_data, randomness, etc.\n",
        "\n",
        "        Returns:\n",
        "            str: The generated response from the API.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If stop sequences are provided.\n",
        "            HTTPError: If the API request fails.\n",
        "        \"\"\"\n",
        "        if stop is not None:\n",
        "            raise ValueError(\"stop kwargs are not permitted.\")\n",
        "\n",
        "        url = \"https://api.worqhat.com/api/ai/content/v2\"\n",
        "\n",
        "        # Include additional parameters for API request\n",
        "        payload = json.dumps({\n",
        "            \"question\": prompt,\n",
        "            \"training_data\": kwargs.get(\"training_data\", \"your name is johnny. when user asks whats your name. say johnny\"),\n",
        "            \"preserve_history\": kwargs.get(\"preserve_history\", False),\n",
        "            \"stream_data\": kwargs.get(\"stream_data\", False),\n",
        "            \"history_object\": kwargs.get(\"history_object\", []),\n",
        "            \"randomness\": kwargs.get(\"randomness\", 0.5),\n",
        "            \"response_type\": kwargs.get(\"response_type\", \"json\"),\n",
        "            **kwargs\n",
        "        })\n",
        "\n",
        "        headers = {\n",
        "            'Content-Type': 'application/json',\n",
        "            'Accept': 'application/json',\n",
        "            # 'Authorization': f'Bearer {os.getenv(\"WORQHAT_API_KEY\")}'  # Load API key from environment variable\n",
        "            'Authorization': f'Bearer sk-02e44d2ccb164c738a6c4a65dbf75e89'  # Load API key from environment variable\n",
        "        }\n",
        "\n",
        "        response = requests.post(url, headers=headers, data=payload)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.text\n",
        "        else:\n",
        "            response.raise_for_status()\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Mapping[str, Any]:\n",
        "        \"\"\"\n",
        "        Returns identifying parameters for instances of this class.\n",
        "\n",
        "        Returns:\n",
        "            Mapping[str, Any]: A dictionary of identifying parameters.\n",
        "        \"\"\"\n",
        "        return {\"n\": self.n}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sZZyBh2wiOqj"
      },
      "outputs": [],
      "source": [
        "llm = CustomLLM(n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "xcI4C90dzsGd",
        "outputId": "2278d9df-a596-4968-d6d2-85b3e7a03ef6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"processing_time\":1674,\"processing_id\":\"0b4cc10b-1ef0-43e7-8f4e-d575e13d3902\",\"processing_count\":132,\"status\":\"success\",\"content\":\"{\\\\n    \\\\\"training_data\\\\\": \\\\\"The training data used to develop this AI model consists of a diverse range of text sources, including but not limited to educational materials, news articles, books, and websites. The model has been trained on a large dataset to generate responses based on the input it receives.\\\\\"\\\\n}\"}'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"Whats your training data?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNgYRCbl6TshLEE7KYekwJa",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
